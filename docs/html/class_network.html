<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>nnlib: Network Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">nnlib
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="class_network-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">Network Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Represents a neural network.  
 <a href="class_network.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="network_8h_source.html">network.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:abb189f45f3baad1a367d4206d67269f3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#abb189f45f3baad1a367d4206d67269f3">Network</a> (size_t inputSize, bool useGPU=true, long long <a class="el" href="class_network.html#a5797bfb98b106399af222c69082073ed">seed</a>=<a class="el" href="network_8h.html#adba0995ed878e291e51428000dfc5dfa">NO_SEED</a>)</td></tr>
<tr class="memdesc:abb189f45f3baad1a367d4206d67269f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Construct a new network.  <a href="class_network.html#abb189f45f3baad1a367d4206d67269f3">More...</a><br /></td></tr>
<tr class="separator:abb189f45f3baad1a367d4206d67269f3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8514cc002fd8cdf043214256be0ca994"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#a8514cc002fd8cdf043214256be0ca994">add</a> (size_t numNeurons, const std::string &amp;activation=&quot;linear&quot;)</td></tr>
<tr class="memdesc:a8514cc002fd8cdf043214256be0ca994"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a new layer to the network.  <a href="class_network.html#a8514cc002fd8cdf043214256be0ca994">More...</a><br /></td></tr>
<tr class="separator:a8514cc002fd8cdf043214256be0ca994"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab96a04290ddb2396a43080e4bf7b277b"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_matrix.html">Matrix</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#ab96a04290ddb2396a43080e4bf7b277b">forward</a> (const <a class="el" href="class_matrix.html">Matrix</a> &amp;batch)</td></tr>
<tr class="memdesc:ab96a04290ddb2396a43080e4bf7b277b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward-propagate a batch through the network.  <a href="class_network.html#ab96a04290ddb2396a43080e4bf7b277b">More...</a><br /></td></tr>
<tr class="separator:ab96a04290ddb2396a43080e4bf7b277b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a69874ed0598be0a616073a0a1c2366"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#a4a69874ed0598be0a616073a0a1c2366">backward</a> (const <a class="el" href="class_matrix.html">Matrix</a> &amp;predicted, const <a class="el" href="class_matrix.html">Matrix</a> &amp;target, <a class="el" href="allocation_8h.html#a3834ad0136a8b95a6589500e4009fe9a">DTYPE</a> learningRate=0.01)</td></tr>
<tr class="memdesc:a4a69874ed0598be0a616073a0a1c2366"><td class="mdescLeft">&#160;</td><td class="mdescRight">Backward-propagate a batch through the network.  <a href="class_network.html#a4a69874ed0598be0a616073a0a1c2366">More...</a><br /></td></tr>
<tr class="separator:a4a69874ed0598be0a616073a0a1c2366"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a303315a1bd86862bac0e5b06bf08f6fc"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#a303315a1bd86862bac0e5b06bf08f6fc">train</a> (const <a class="el" href="class_matrix.html">Matrix</a> &amp;X, const <a class="el" href="class_matrix.html">Matrix</a> &amp;y, int epochs, size_t batchSize=<a class="el" href="layer_8h.html#a123fa013ecd2c91686ad58c0b8d985b3">DEFAULT_BATCH_SIZE</a>, <a class="el" href="allocation_8h.html#a3834ad0136a8b95a6589500e4009fe9a">DTYPE</a> learningRate=0.01)</td></tr>
<tr class="memdesc:a303315a1bd86862bac0e5b06bf08f6fc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the network.  <a href="class_network.html#a303315a1bd86862bac0e5b06bf08f6fc">More...</a><br /></td></tr>
<tr class="separator:a303315a1bd86862bac0e5b06bf08f6fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-methods" name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:a27c86f9946b5cf76d5caf25af8af9db9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#a27c86f9946b5cf76d5caf25af8af9db9">processEpoch</a> (std::vector&lt; <a class="el" href="class_matrix.html">Matrix</a> &gt; &amp;batches, std::vector&lt; <a class="el" href="class_matrix.html">Matrix</a> &gt; &amp;targets, <a class="el" href="class_matrix.html">Matrix</a> &amp;yHost, <a class="el" href="allocation_8h.html#a3834ad0136a8b95a6589500e4009fe9a">DTYPE</a> learningRate)</td></tr>
<tr class="memdesc:a27c86f9946b5cf76d5caf25af8af9db9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Trains the model on a single epoch.  <a href="class_network.html#a27c86f9946b5cf76d5caf25af8af9db9">More...</a><br /></td></tr>
<tr class="separator:a27c86f9946b5cf76d5caf25af8af9db9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pri-attribs" name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a0bf126265345f2e6aa85aeeffa2f9afd"><td class="memItemLeft" align="right" valign="top">DataLocation&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#a0bf126265345f2e6aa85aeeffa2f9afd">location</a></td></tr>
<tr class="memdesc:a0bf126265345f2e6aa85aeeffa2f9afd"><td class="mdescLeft">&#160;</td><td class="mdescRight">The location of the network.  <a href="class_network.html#a0bf126265345f2e6aa85aeeffa2f9afd">More...</a><br /></td></tr>
<tr class="separator:a0bf126265345f2e6aa85aeeffa2f9afd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af75849d87721bf356380855281c11852"><td class="memItemLeft" align="right" valign="top"><a class="el" href="class_matrix.html">Matrix</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#af75849d87721bf356380855281c11852">loss</a></td></tr>
<tr class="memdesc:af75849d87721bf356380855281c11852"><td class="mdescLeft">&#160;</td><td class="mdescRight">Pre-allocated space for loss.  <a href="class_network.html#af75849d87721bf356380855281c11852">More...</a><br /></td></tr>
<tr class="separator:af75849d87721bf356380855281c11852"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50f4a527788dfa71d67984a939ed3ee5"><td class="memItemLeft" align="right" valign="top"><a id="a50f4a527788dfa71d67984a939ed3ee5" name="a50f4a527788dfa71d67984a939ed3ee5"></a>
std::vector&lt; <a class="el" href="class_layer.html">Layer</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>layers</b></td></tr>
<tr class="memdesc:a50f4a527788dfa71d67984a939ed3ee5"><td class="mdescLeft">&#160;</td><td class="mdescRight">List of network layers. <br /></td></tr>
<tr class="separator:a50f4a527788dfa71d67984a939ed3ee5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5797bfb98b106399af222c69082073ed"><td class="memItemLeft" align="right" valign="top"><a id="a5797bfb98b106399af222c69082073ed" name="a5797bfb98b106399af222c69082073ed"></a>
long long&#160;</td><td class="memItemRight" valign="bottom"><b>seed</b></td></tr>
<tr class="memdesc:a5797bfb98b106399af222c69082073ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">Seed used for random initialization. <br /></td></tr>
<tr class="separator:a5797bfb98b106399af222c69082073ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa09d16878ecb7f6fe09dd3d5d0f919b6"><td class="memItemLeft" align="right" valign="top">size_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_network.html#aa09d16878ecb7f6fe09dd3d5d0f919b6">previousSize</a></td></tr>
<tr class="memdesc:aa09d16878ecb7f6fe09dd3d5d0f919b6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Keeps track of the size of the previous layer.  <a href="class_network.html#aa09d16878ecb7f6fe09dd3d5d0f919b6">More...</a><br /></td></tr>
<tr class="separator:aa09d16878ecb7f6fe09dd3d5d0f919b6"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p >Represents a neural network. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="abb189f45f3baad1a367d4206d67269f3" name="abb189f45f3baad1a367d4206d67269f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abb189f45f3baad1a367d4206d67269f3">&#9670;&nbsp;</a></span>Network()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Network::Network </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>inputSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>useGPU</em> = <code>true</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">long long&#160;</td>
          <td class="paramname"><em>seed</em> = <code><a class="el" href="network_8h.html#adba0995ed878e291e51428000dfc5dfa">NO_SEED</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Construct a new network. </p>
<p >The constructed network can use GPU acceleration if a GPU and CUDA are available, and the <code>useGPU</code> parameter is set to true.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputSize</td><td>The number of inputs to the neural network. </td></tr>
    <tr><td class="paramname">useGPU</td><td>Boolean to specify whether the network should use GPU acceleration. </td></tr>
    <tr><td class="paramname">seed</td><td>Seed that should be used for random initialization of the network. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a8514cc002fd8cdf043214256be0ca994" name="a8514cc002fd8cdf043214256be0ca994"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8514cc002fd8cdf043214256be0ca994">&#9670;&nbsp;</a></span>add()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Network::add </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>numNeurons</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>activation</em> = <code>&quot;linear&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Add a new layer to the network. </p>
<p >Three activation functions can be used: Linear, ReLU and Sigmoid. The activation can be selected by specifying the activation parameter, using one of the strings: "linear", "relu" or "sigmoid". If any other string is specified, Linear activation will be used.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">numNeurons</td><td>The number of neurons the new layer should contain. </td></tr>
    <tr><td class="paramname">activation</td><td>The activation function to use. Can be "linear", "relu" or "sigmoid". </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a4a69874ed0598be0a616073a0a1c2366" name="a4a69874ed0598be0a616073a0a1c2366"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a69874ed0598be0a616073a0a1c2366">&#9670;&nbsp;</a></span>backward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Network::backward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_matrix.html">Matrix</a> &amp;&#160;</td>
          <td class="paramname"><em>predicted</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_matrix.html">Matrix</a> &amp;&#160;</td>
          <td class="paramname"><em>target</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="allocation_8h.html#a3834ad0136a8b95a6589500e4009fe9a">DTYPE</a>&#160;</td>
          <td class="paramname"><em>learningRate</em> = <code>0.01</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Backward-propagate a batch through the network. </p>
<p >Squared error loss is used as the loss metric. The network first calculates the gradients on all layers and only then applies them. This is because layers require weights from following layers to compute the correct gradients.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">predicted</td><td>The predictions of the network as retrieved from <a class="el" href="class_network.html#ab96a04290ddb2396a43080e4bf7b277b" title="Forward-propagate a batch through the network.">Network::forward</a>. </td></tr>
    <tr><td class="paramname">target</td><td>The targets for that batch of data. </td></tr>
    <tr><td class="paramname">learningRate</td><td>The learning rate of the model. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ab96a04290ddb2396a43080e4bf7b277b" name="ab96a04290ddb2396a43080e4bf7b277b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab96a04290ddb2396a43080e4bf7b277b">&#9670;&nbsp;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_matrix.html">Matrix</a> * Network::forward </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_matrix.html">Matrix</a> &amp;&#160;</td>
          <td class="paramname"><em>batch</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Forward-propagate a batch through the network. </p>
<p >The samples should be aligned along the first axis.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batch</td><td>The batch to propagate. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The pointer to the output of the network. This returns <a class="el" href="class_layer.html#af0845a71fb5abcfc54a9bfc67fa771e1" title="The output of the layer before applying the activation function.">Layer::aMatrix</a> of the last layer. </dd></dl>

</div>
</div>
<a id="a27c86f9946b5cf76d5caf25af8af9db9" name="a27c86f9946b5cf76d5caf25af8af9db9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a27c86f9946b5cf76d5caf25af8af9db9">&#9670;&nbsp;</a></span>processEpoch()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void Network::processEpoch </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; <a class="el" href="class_matrix.html">Matrix</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>batches</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::vector&lt; <a class="el" href="class_matrix.html">Matrix</a> &gt; &amp;&#160;</td>
          <td class="paramname"><em>targets</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="class_matrix.html">Matrix</a> &amp;&#160;</td>
          <td class="paramname"><em>yHost</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="allocation_8h.html#a3834ad0136a8b95a6589500e4009fe9a">DTYPE</a>&#160;</td>
          <td class="paramname"><em>learningRate</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Trains the model on a single epoch. </p>
<p >Helper method used in <a class="el" href="class_network.html#a303315a1bd86862bac0e5b06bf08f6fc" title="Train the network.">Network::train()</a>. The method computes accuracy, which is why yHost is passed as an argument. In this way, when the network is running on GPU, the targets will not have to be copied to host memory when computing accuracy.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">batches</td><td>The list of batches to process. These have been split in <a class="el" href="class_network.html#a303315a1bd86862bac0e5b06bf08f6fc" title="Train the network.">Network::train()</a> method. </td></tr>
    <tr><td class="paramname">targets</td><td>The list of targets to process. These have been split in <a class="el" href="class_network.html#a303315a1bd86862bac0e5b06bf08f6fc" title="Train the network.">Network::train()</a> method. </td></tr>
    <tr><td class="paramname">yHost</td><td><a class="el" href="class_matrix.html" title="Represents a matrix (2D array).">Matrix</a> that stores the whole y array on host. </td></tr>
    <tr><td class="paramname">learningRate</td><td>The learning rate used during training. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a303315a1bd86862bac0e5b06bf08f6fc" name="a303315a1bd86862bac0e5b06bf08f6fc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a303315a1bd86862bac0e5b06bf08f6fc">&#9670;&nbsp;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Network::train </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="class_matrix.html">Matrix</a> &amp;&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="class_matrix.html">Matrix</a> &amp;&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>epochs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>batchSize</em> = <code><a class="el" href="layer_8h.html#a123fa013ecd2c91686ad58c0b8d985b3">DEFAULT_BATCH_SIZE</a></code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="allocation_8h.html#a3834ad0136a8b95a6589500e4009fe9a">DTYPE</a>&#160;</td>
          <td class="paramname"><em>learningRate</em> = <code>0.01</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Train the network. </p>
<p >Both X and y should have the data samples aligned on the first axis. Each row in X should be aligned with the corresponding row in y.</p>
<p >The only supported metric for now is accuracy, which is calculated by default by the method. Furthermore, the method displays the progress of each epoch, including time spent and accuracy.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X</td><td>The data to train the network on. </td></tr>
    <tr><td class="paramname">y</td><td>The targets of the network. </td></tr>
    <tr><td class="paramname">epochs</td><td>The number of epochs to train the network for. </td></tr>
    <tr><td class="paramname">batchSize</td><td>The size of the batch. </td></tr>
    <tr><td class="paramname">learningRate</td><td>The learning rate of the algorithm. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a0bf126265345f2e6aa85aeeffa2f9afd" name="a0bf126265345f2e6aa85aeeffa2f9afd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0bf126265345f2e6aa85aeeffa2f9afd">&#9670;&nbsp;</a></span>location</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">DataLocation Network::location</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The location of the network. </p>
<p >Specifies the location of all the data used by the network. See DataLocation for more info. </p>

</div>
</div>
<a id="af75849d87721bf356380855281c11852" name="af75849d87721bf356380855281c11852"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af75849d87721bf356380855281c11852">&#9670;&nbsp;</a></span>loss</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="class_matrix.html">Matrix</a> Network::loss</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Pre-allocated space for loss. </p>
<p >Might require resizing/reallocating if <code>batchSize</code> != <a class="el" href="layer_8h.html#a123fa013ecd2c91686ad58c0b8d985b3" title="The default batch size if no batch size is specified.">DEFAULT_BATCH_SIZE</a> during training. In that case, the reshaping will still only happen once. The data is pre-allocated to avoid unnecessary allocation during runtime. </p>

</div>
</div>
<a id="aa09d16878ecb7f6fe09dd3d5d0f919b6" name="aa09d16878ecb7f6fe09dd3d5d0f919b6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa09d16878ecb7f6fe09dd3d5d0f919b6">&#9670;&nbsp;</a></span>previousSize</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">size_t Network::previousSize</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Keeps track of the size of the previous layer. </p>
<p >Layers need to know the size of the input passed to them. This is achieved using this variable, that keeps track of the size of the previous layer (or size of the input if in 1st layer). In this way, layers can pre-allocate required space during initialization. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/<a class="el" href="network_8h_source.html">network.h</a></li>
<li>src/ann/network.cpp</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.4
</small></address>
</body>
</html>
